{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCOHITOBssKnZnVlWrskCM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galenzo17/AI-personal-test/blob/main/Medical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Li93vT-B-lu"
      },
      "outputs": [],
      "source": [
        "# Complete Python Script for Drug Classification and Counting in a Hospital Cabinet\n",
        "\n",
        "# Step 1: Install Necessary Libraries\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# List of required packages\n",
        "required_packages = [\"pandas\", \"numpy\", \"scikit-learn\", \"joblib\"]\n",
        "\n",
        "# Install missing packages\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        install_package(package)\n",
        "\n",
        "# Step 2: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import classification_report, mean_absolute_error\n",
        "import joblib\n",
        "\n",
        "# Step 3: Load the Dataset\n",
        "# Ensure 'medical_data.csv' is in the same directory as this script\n",
        "try:\n",
        "    data = pd.read_csv('medical_data.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'medical_data.csv' not found in the current directory.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Step 4: Explore the Dataset\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nDataset Information:\")\n",
        "print(data.info())\n",
        "\n",
        "# Step 5: Data Preprocessing\n",
        "# Handle missing values by dropping rows with any missing values\n",
        "data_clean = data.dropna()\n",
        "print(f\"\\nDataset shape after dropping missing values: {data_clean.shape}\")\n",
        "\n",
        "# Ensure required columns exist\n",
        "required_columns = ['drug', 'quantity']\n",
        "for column in required_columns:\n",
        "    if column not in data_clean.columns:\n",
        "        print(f\"Error: Required column '{column}' not found in the dataset.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "# Separate features and target for classification\n",
        "X_classification = data_clean.drop(['drug', 'quantity'], axis=1)\n",
        "y_classification = data_clean['drug']\n",
        "\n",
        "# Encode target labels for classification\n",
        "label_encoder = LabelEncoder()\n",
        "y_classification_encoded = label_encoder.fit_transform(y_classification)\n",
        "\n",
        "# Separate features and target for regression (counting)\n",
        "X_regression = data_clean.drop(['drug', 'quantity'], axis=1)\n",
        "y_regression = data_clean['quantity']\n",
        "\n",
        "# Handle categorical features by encoding them\n",
        "X_classification_encoded = pd.get_dummies(X_classification, drop_first=True)\n",
        "X_regression_encoded = pd.get_dummies(X_regression, drop_first=True)\n",
        "\n",
        "# Step 6: Split the Data into Training and Testing Sets\n",
        "\n",
        "# For Classification\n",
        "X_train_clas, X_test_clas, y_train_clas, y_test_clas = train_test_split(\n",
        "    X_classification_encoded, y_classification_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# For Regression\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_regression_encoded, y_regression, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 7: Feature Scaling\n",
        "scaler_clas = StandardScaler()\n",
        "X_train_clas_scaled = scaler_clas.fit_transform(X_train_clas)\n",
        "X_test_clas_scaled = scaler_clas.transform(X_test_clas)\n",
        "\n",
        "scaler_reg = StandardScaler()\n",
        "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
        "\n",
        "# Step 8: Train the Classification Model\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "classifier.fit(X_train_clas_scaled, y_train_clas)\n",
        "print(\"\\nClassification model trained successfully.\")\n",
        "\n",
        "# Step 9: Evaluate the Classification Model\n",
        "y_pred_clas = classifier.predict(X_test_clas_scaled)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_clas, y_pred_clas, target_names=label_encoder.classes_))\n",
        "\n",
        "# Step 10: Train the Regression Model\n",
        "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "regressor.fit(X_train_reg_scaled, y_train_reg)\n",
        "print(\"Regression model trained successfully.\")\n",
        "\n",
        "# Step 11: Evaluate the Regression Model\n",
        "y_pred_reg = regressor.predict(X_test_reg_scaled)\n",
        "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "print(f\"\\nMean Absolute Error for Quantity Prediction: {mae:.2f}\")\n",
        "\n",
        "# Step 12: Save the Trained Models\n",
        "joblib.dump(classifier, 'drug_classification_model.pkl')\n",
        "joblib.dump(regressor, 'drug_quantity_regressor.pkl')\n",
        "joblib.dump(scaler_clas, 'scaler_classification.pkl')\n",
        "joblib.dump(scaler_reg, 'scaler_regression.pkl')\n",
        "print(\"\\nModels and scalers saved successfully.\")\n",
        "\n",
        "# Optional: Function to Load and Use the Models\n",
        "def predict_new_data(new_data):\n",
        "    \"\"\"\n",
        "    Predicts the drug classification and quantity for new data.\n",
        "\n",
        "    Parameters:\n",
        "    new_data (pd.DataFrame): New data with the same features as the training data.\n",
        "\n",
        "    Returns:\n",
        "    tuple: (predicted_drug, predicted_quantity)\n",
        "    \"\"\"\n",
        "    # Load models and scalers\n",
        "    clf = joblib.load('drug_classification_model.pkl')\n",
        "    reg = joblib.load('drug_quantity_regressor.pkl')\n",
        "    scaler_c = joblib.load('scaler_classification.pkl')\n",
        "    scaler_r = joblib.load('scaler_regression.pkl')\n",
        "    le = label_encoder  # Assuming label_encoder is available\n",
        "\n",
        "    # Encode categorical features\n",
        "    new_data_encoded = pd.get_dummies(new_data, drop_first=True)\n",
        "\n",
        "    # Align the new data with training data columns\n",
        "    new_data_encoded = new_data_encoded.reindex(columns=X_classification_encoded.columns, fill_value=0)\n",
        "\n",
        "    # Scale features\n",
        "    new_data_scaled_clas = scaler_c.transform(new_data_encoded)\n",
        "    new_data_scaled_reg = scaler_r.transform(new_data_encoded)\n",
        "\n",
        "    # Predict\n",
        "    pred_clas = clf.predict(new_data_scaled_clas)\n",
        "    pred_reg = reg.predict(new_data_scaled_reg)\n",
        "\n",
        "    # Decode classification labels\n",
        "    pred_drug = le.inverse_transform(pred_clas)\n",
        "\n",
        "    return pred_drug, pred_reg\n",
        "\n",
        "# Example Usage of predict_new_data (Uncomment and modify as needed)\n",
        "# new_sample = pd.DataFrame({\n",
        "#     'feature1': [value1],\n",
        "#     'feature2': [value2],\n",
        "#     # Add all necessary features\n",
        "# })\n",
        "# predicted_drug, predicted_quantity = predict_new_data(new_sample)\n",
        "# print(f\"Predicted Drug: {predicted_drug[0]}, Predicted Quantity: {predicted_quantity[0]:.2f}\")"
      ]
    }
  ]
}