{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAGlL5kzCzssfNDrWipGzG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galenzo17/AI-personal-test/blob/main/audio_clasifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8CQgr378U_K"
      },
      "outputs": [],
      "source": [
        "# Instalar dependencias\n",
        "!pip install tensorflow librosa\n",
        "\n",
        "# Importar bibliotecas necesarias\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Descargar y preparar el conjunto de datos\n",
        "# Para este ejemplo, asumimos que tienes un conjunto de datos con archivos de audio de ladridos y maullidos\n",
        "# Organiza tus datos en carpetas 'perro' y 'gato' dentro de una carpeta 'datos'\n",
        "# Sube la carpeta 'datos' a tu Google Drive y móntalo en Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta a la carpeta de datos\n",
        "data_path = '/content/drive/My Drive/datos/'\n",
        "\n",
        "# Función para extraer características de los archivos de audio\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, resample=True)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {file_path}: {e}\")\n",
        "        return None\n",
        "    return mfccs_scaled\n",
        "\n",
        "# Preparar datos y etiquetas\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for label in ['perro', 'gato']:\n",
        "    folder_path = os.path.join(data_path, label)\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        data = extract_features(file_path)\n",
        "        if data is not None:\n",
        "            features.append(data)\n",
        "            labels.append(label)\n",
        "\n",
        "# Convertir a arrays de numpy\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Codificar etiquetas\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Construir el modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(40,), activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluar el modelo\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Precisión en el conjunto de prueba: {test_acc:.2f}')"
      ]
    }
  ]
}