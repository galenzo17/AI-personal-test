{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAWCQjRISAjKDUUvjBQUtR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galenzo17/AI-personal-test/blob/main/Real_time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnrgyYW3On1W"
      },
      "outputs": [],
      "source": [
        "# Instalar las librerías necesarias\n",
        "!pip install opencv-python\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Descargar los pesos pre-entrenados del modelo SAM\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
        "\n",
        "# Importar las librerías\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "from base64 import b64decode\n",
        "%matplotlib inline\n",
        "\n",
        "# Configurar el modelo SAM\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_type = \"vit_b\"\n",
        "sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "\n",
        "# Descargar el filtro (ojos de gato)\n",
        "!wget https://i.imgur.com/8fj6G9M.png -O cat_eyes.png\n",
        "\n",
        "# Cargar el filtro\n",
        "cat_eyes = cv2.imread('cat_eyes.png', cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "# Función para capturar imagen desde la webcam\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const video = document.createElement('video');\n",
        "        const btn = document.createElement('button');\n",
        "        btn.textContent = 'Tomar foto';\n",
        "        div.appendChild(video);\n",
        "        div.appendChild(btn);\n",
        "        document.body.appendChild(div);\n",
        "\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Esperar a que el usuario haga clic\n",
        "        await new Promise((resolve) => btn.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "        return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    img = cv2.imread(filename)\n",
        "    return img\n",
        "\n",
        "# Capturar la imagen\n",
        "frame = take_photo()\n",
        "\n",
        "# Convertir la imagen a RGB\n",
        "frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Generar las máscaras\n",
        "masks = mask_generator.generate(frame_rgb)\n",
        "\n",
        "# Seleccionar la máscara más grande\n",
        "if len(masks) > 0:\n",
        "    masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
        "    mask = masks[0]['segmentation']\n",
        "else:\n",
        "    mask = np.zeros(frame.shape[:2], dtype=bool)\n",
        "\n",
        "# Superponer el filtro en la región segmentada\n",
        "contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "if contours:\n",
        "    x, y, w, h = cv2.boundingRect(contours[0])\n",
        "    filter_resized = cv2.resize(cat_eyes, (w, int(cat_eyes.shape[0] * w / cat_eyes.shape[1])))\n",
        "    fh, fw = filter_resized.shape[:2]\n",
        "    x_offset = x\n",
        "    y_offset = y + int(h/4)  # Ajuste vertical\n",
        "    if y_offset + fh > frame.shape[0]:\n",
        "        fh = frame.shape[0] - y_offset\n",
        "        filter_resized = filter_resized[:fh]\n",
        "    if x_offset + fw > frame.shape[1]:\n",
        "        fw = frame.shape[1] - x_offset\n",
        "        filter_resized = filter_resized[:, :fw]\n",
        "    # Superponer el filtro\n",
        "    alpha_s = filter_resized[:, :, 3] / 255.0\n",
        "    alpha_l = 1.0 - alpha_s\n",
        "    for c in range(0, 3):\n",
        "        frame[y_offset:y_offset+fh, x_offset:x_offset+fw, c] = (alpha_s * filter_resized[:, :, c] + alpha_l * frame[y_offset:y_offset+fh, x_offset:x_offset+fw, c])\n",
        "\n",
        "# Mostrar el resultado\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ]
}