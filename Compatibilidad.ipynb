{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8Jp/lO3CrflAg8eRybUSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galenzo17/AI-personal-test/blob/main/Compatibilidad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVD4qxL2aG_o"
      },
      "outputs": [],
      "source": [
        "# 1. Instalación de dependencias\n",
        "!pip install -q kaggle\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q pandas\n",
        "!pip install -q numpy\n",
        "!pip install -q tensorflow\n",
        "!pip install -q matplotlib\n",
        "!pip install -q seaborn\n",
        "\n",
        "# 2. Configuración de la API de Kaggle\n",
        "# Necesitas subir tu archivo kaggle.json que puedes obtener desde tu cuenta de Kaggle\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Subir el archivo kaggle.json\n",
        "print(\"Por favor, sube tu archivo kaggle.json para acceder a los datos de Kaggle.\")\n",
        "files.upload()\n",
        "\n",
        "# Crear la carpeta de Kaggle y mover el archivo\n",
        "os.makedirs('/root/.kaggle/', exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "os.chmod('/root/.kaggle/kaggle.json', 600)\n",
        "\n",
        "# 3. Descargar el conjunto de datos desde Kaggle\n",
        "# Reemplaza 'username/dataset-name' con el identificador de tu conjunto de datos\n",
        "# Por ejemplo: 'zynicide/wine-reviews'\n",
        "# Asegúrate de que el conjunto de datos contiene la información necesaria para las habitaciones y residentes\n",
        "\n",
        "# Ejemplo:\n",
        "# !kaggle datasets download -d username/dataset-name\n",
        "\n",
        "# Para este ejemplo, supongamos que el dataset se llama 'roommate-compatibility'\n",
        "# !kaggle datasets download -d yourusername/roommate-compatibility\n",
        "\n",
        "# Descomprimir el archivo descargado\n",
        "# !unzip roommate-compatibility.zip\n",
        "\n",
        "# Nota: Asegúrate de reemplazar con el nombre correcto del archivo\n",
        "\n",
        "# 4. Cargar y preprocesar los datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el dataset\n",
        "# Supongamos que el archivo es 'roommate_data.csv'\n",
        "# Asegúrate de que el archivo esté en el directorio de trabajo\n",
        "# Si está en otra carpeta, proporciona la ruta correcta\n",
        "\n",
        "try:\n",
        "    data = pd.read_csv('roommate_data.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo 'roommate_data.csv' no se encontró. Por favor, verifica el nombre y la ubicación del archivo.\")\n",
        "\n",
        "# Exploración básica de los datos\n",
        "print(\"Primeras filas del dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nInformación del dataset:\")\n",
        "print(data.info())\n",
        "\n",
        "print(\"\\nDescripción estadística:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Manejo de valores faltantes\n",
        "print(\"\\nValores faltantes por columna:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Opcional: Puedes decidir cómo manejar los valores faltantes\n",
        "# Por ejemplo, eliminar filas con valores faltantes\n",
        "data = data.dropna()\n",
        "\n",
        "# Codificación de variables categóricas\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Identifica las columnas categóricas\n",
        "categorical_cols = ['gusta_noche', 'gusta_dia', 'vida_social', 'trabaja_remoto']  # Añade más según tu dataset\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "\n",
        "# Separar características y etiqueta\n",
        "# Supongamos que la etiqueta es 'compatibilidad' (1 compatible, 0 no compatible)\n",
        "X = data.drop('compatibilidad', axis=1)\n",
        "y = data['compatibilidad']\n",
        "\n",
        "# División en conjuntos de entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalado de características\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 5. Entrenamiento del modelo\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Definir el modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nPrecisión en el conjunto de prueba: {accuracy*100:.2f}%\")\n",
        "\n",
        "# 6. Visualización de resultados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Pérdida durante el entrenamiento\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de Validación')\n",
        "plt.title('Pérdida del Modelo')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "\n",
        "# Precisión durante el entrenamiento\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='Precisión de Entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Precisión de Validación')\n",
        "plt.title('Precisión del Modelo')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 7. Función de recomendación\n",
        "def recomendar_habitacion(inputs):\n",
        "    \"\"\"\n",
        "    Recibe un diccionario con las características del usuario y recomienda la compatibilidad.\n",
        "\n",
        "    Parámetros:\n",
        "    inputs (dict): Diccionario con las siguientes claves:\n",
        "        - 'gusta_noche': 'si' o 'no'\n",
        "        - 'gusta_dia': 'si' o 'no'\n",
        "        - 'vida_social': 'alta', 'media', 'baja'\n",
        "        - 'trabaja_remoto': 'si' o 'no'\n",
        "        # Añade más características según tu formulario\n",
        "\n",
        "    Retorna:\n",
        "    compatibilidad (float): Probabilidad de compatibilidad.\n",
        "    \"\"\"\n",
        "    # Convertir las entradas en un DataFrame\n",
        "    input_df = pd.DataFrame([inputs])\n",
        "\n",
        "    # Codificar las variables categóricas\n",
        "    for col in categorical_cols:\n",
        "        input_df[col] = le.transform(input_df[col])\n",
        "\n",
        "    # Escalar las características\n",
        "    input_scaled = scaler.transform(input_df)\n",
        "\n",
        "    # Hacer la predicción\n",
        "    compatibilidad = model.predict(input_scaled)[0][0]\n",
        "\n",
        "    return compatibilidad\n",
        "\n",
        "# 8. Ejemplo de uso de la función de recomendación\n",
        "# Definir las entradas del usuario\n",
        "entrada_usuario = {\n",
        "    'gusta_noche': 'si',\n",
        "    'gusta_dia': 'no',\n",
        "    'vida_social': 'alta',\n",
        "    'trabaja_remoto': 'si'\n",
        "    # Añade más características según tu formulario\n",
        "}\n",
        "\n",
        "# Obtener la compatibilidad\n",
        "compatibilidad = recomendar_habitacion(entrada_usuario)\n",
        "print(f\"\\nProbabilidad de compatibilidad: {compatibilidad*100:.2f}%\")\n",
        "\n",
        "# Interpretación de la compatibilidad\n",
        "if compatibilidad >= 0.7:\n",
        "    print(\"Alta compatibilidad. Se recomienda esta habitación.\")\n",
        "elif compatibilidad >= 0.4:\n",
        "    print(\"Compatibilidad media. Requiere revisión adicional.\")\n",
        "else:\n",
        "    print(\"Baja compatibilidad. Se desaconseja esta habitación.\")"
      ]
    }
  ]
}