{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhX13W/zhANPJ9268zMbmz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galenzo17/AI-personal-test/blob/main/Newcresitrisk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4xZb8qcBK_b"
      },
      "outputs": [],
      "source": [
        "# Instalación de dependencias\n",
        "!pip install pandas numpy scikit-learn tensorflow seaborn\n",
        "\n",
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Descargar datos de Kaggle\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()  # Subir archivo kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d uciml/german-credit\n",
        "!unzip german-credit.zip\n",
        "\n",
        "# Cargar y preparar datos\n",
        "df = pd.read_csv('german_credit_data.csv')\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "# Eliminar valores nulos\n",
        "df = df.dropna()\n",
        "\n",
        "# Codificar variables categóricas\n",
        "le = LabelEncoder()\n",
        "categorical_columns = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose']\n",
        "for column in categorical_columns:\n",
        "    df[column] = le.fit_transform(df[column].astype(str))\n",
        "\n",
        "# Separar features y target\n",
        "X = df.drop(['Risk'], axis=1)\n",
        "y = df['Risk']\n",
        "\n",
        "# Normalizar datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Dividir datos en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear modelo de red neuronal\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Configurar early stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Entrenar modelo\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluar modelo\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'\\nTest accuracy: {test_accuracy:.3f}')\n",
        "\n",
        "# Visualizar resultados del entrenamiento\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Realizar predicciones\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Generar matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Imprimir reporte de clasificación\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, y_pred_classes))\n",
        "\n",
        "# Guardar el modelo\n",
        "model.save('modelo_riesgo_crediticio.h5')\n",
        "print('\\nModelo guardado como \"modelo_riesgo_crediticio.h5\"')\n",
        "\n",
        "# Ejemplo de cómo usar el modelo para nuevas predicciones\n",
        "def predecir_riesgo(datos_cliente):\n",
        "    # Asegurarse que los datos estén en el mismo formato que los datos de entrenamiento\n",
        "    datos_escalados = scaler.transform([datos_cliente])\n",
        "    prediccion = model.predict(datos_escalados)\n",
        "    return \"Alto Riesgo\" if prediccion[0][0] > 0.5 else \"Bajo Riesgo\"\n",
        "\n",
        "# Ejemplo de uso\n",
        "nuevo_cliente = [1, 2, 1, 2, 1000, 12, 4, 1, 2, 24]  # Valores ejemplo\n",
        "resultado = predecir_riesgo(nuevo_cliente)\n",
        "print(f'\\nPredicción para nuevo cliente: {resultado}')"
      ]
    }
  ]
}